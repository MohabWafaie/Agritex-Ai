{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93e40352-a862-4af2-a170-26a9e1680ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aliof\\anacondaLocation\\envs\\tourchgpu\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\aliof\\anacondaLocation\\envs\\tourchgpu\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Epoch 1/50: 100%|█████████████████████████████████| 1500/1500 [16:12<00:00,  1.54it/s, Train Loss=0.2, Train Acc=0.936]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Val Loss: 0.0892, Val Acc: 0.9730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|██████████████████████████████| 1500/1500 [14:50<00:00,  1.68it/s, Train Loss=0.0714, Train Acc=0.979]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Val Loss: 0.1066, Val Acc: 0.9707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: 100%|██████████████████████████████| 1500/1500 [19:03<00:00,  1.31it/s, Train Loss=0.0535, Train Acc=0.985]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], Val Loss: 0.0454, Val Acc: 0.9869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: 100%|██████████████████████████████| 1500/1500 [14:49<00:00,  1.69it/s, Train Loss=0.0413, Train Acc=0.988]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], Val Loss: 0.0557, Val Acc: 0.9807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: 100%|███████████████████████████████| 1500/1500 [14:49<00:00,  1.69it/s, Train Loss=0.0345, Train Acc=0.99]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Val Loss: 0.0409, Val Acc: 0.9892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: 100%|███████████████████████████████| 1500/1500 [14:53<00:00,  1.68it/s, Train Loss=0.0357, Train Acc=0.99]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], Val Loss: 0.0433, Val Acc: 0.9895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: 100%|██████████████████████████████| 1500/1500 [14:53<00:00,  1.68it/s, Train Loss=0.0275, Train Acc=0.993]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50], Val Loss: 0.0361, Val Acc: 0.9913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50: 100%|██████████████████████████████| 1500/1500 [14:55<00:00,  1.68it/s, Train Loss=0.0222, Train Acc=0.994]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Val Loss: 0.0370, Val Acc: 0.9913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50: 100%|███████████████████████████████| 1500/1500 [14:49<00:00,  1.69it/s, Train Loss=0.024, Train Acc=0.994]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50], Val Loss: 0.0519, Val Acc: 0.9905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50: 100%|█████████████████████████████| 1500/1500 [14:49<00:00,  1.69it/s, Train Loss=0.0265, Train Acc=0.994]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Val Loss: 0.0508, Val Acc: 0.9892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50: 100%|█████████████████████████████| 1500/1500 [15:01<00:00,  1.66it/s, Train Loss=0.0206, Train Acc=0.994]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50], Val Loss: 0.0453, Val Acc: 0.9915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50: 100%|█████████████████████████████| 1500/1500 [14:55<00:00,  1.68it/s, Train Loss=0.0203, Train Acc=0.994]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50], Val Loss: 0.0402, Val Acc: 0.9943\n",
      "Validation loss hasn't improved for 5 epochs. Early stopping...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "import torch.cuda.amp as amp  # Import mixed precision module\n",
    "\n",
    "# Define transforms for preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize the image to 224x224\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load your datasets\n",
    "train_dataset = datasets.ImageFolder(root=r\"C:\\Users\\aliof\\OneDrive\\Desktop\\processed resized data\\augmented ali data\\balanced_dataset\\train\", transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root=r\"C:\\Users\\aliof\\OneDrive\\Desktop\\processed resized data\\augmented ali data\\balanced_dataset\\valid\", transform=transform)\n",
    "\n",
    "# Define the model\n",
    "class ModifiedVGG16(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ModifiedVGG16, self).__init__()\n",
    "        self.features = torchvision.models.vgg16(pretrained=True).features\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 1 * 1, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes),  # Fix here\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "num_classes = len(train_dataset.classes)  # Define the number of classes\n",
    "model = ModifiedVGG16(num_classes)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Mixed precision training\n",
    "scaler = amp.GradScaler()  # Initialize the gradient scaler\n",
    "\n",
    "# Define data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)  # Decrease batch size\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)  # Decrease batch size\n",
    "\n",
    "# Training loop with early stopping\n",
    "num_epochs = 50\n",
    "best_val_loss = float('inf')\n",
    "patience = 5\n",
    "current_patience = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "    for i, (inputs, targets) in enumerate(pbar, 1):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Mixed precision training\n",
    "        with amp.autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "\n",
    "        # Update tqdm description\n",
    "        train_loss = running_loss / i\n",
    "        train_accuracy = correct / total\n",
    "        pbar.set_postfix({'Train Loss': train_loss, 'Train Acc': train_accuracy})\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, predicted_val = torch.max(outputs, 1)\n",
    "            total_val += targets.size(0)\n",
    "            correct_val += (predicted_val == targets).sum().item()\n",
    "\n",
    "    val_loss /= len(val_dataset)\n",
    "    val_accuracy = correct_val / total_val\n",
    "\n",
    "    tqdm.write(f'Epoch [{epoch+1}/{num_epochs}], Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}')\n",
    "\n",
    "    # Check for early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), r\"C:\\Users\\aliof\\models\\vgg16\\best_model_paper.pt\")\n",
    "        current_patience = 0\n",
    "    else:\n",
    "        current_patience += 1\n",
    "\n",
    "    if current_patience == patience:\n",
    "        tqdm.write(f\"Validation loss hasn't improved for {patience} epochs. Early stopping...\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a97b73a-da8f-4502-a5a1-3a3c271fc2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLOPS: 15365.58 million\n",
      "Number of parameters: 33.65 million\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from thop import profile\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the model\n",
    "class ModifiedVGG16(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ModifiedVGG16, self).__init__()\n",
    "        self.features = torchvision.models.vgg16(pretrained=True).features\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 1 * 1, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes),  # Fix here\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "num_classes = 12\n",
    "model = ModifiedVGG16(num_classes)\n",
    "\n",
    "#load our trained model\n",
    "model.load_state_dict(torch.load(r\"C:\\Users\\aliof\\models\\vgg16\\best_model_paper.pt\"))\n",
    "\n",
    "# Define input tensor shape (batch_size, channels, height, width)\n",
    "input_shape = (1, 3, 224, 224)  # Assuming input images are RGB with size 224x224\n",
    "\n",
    "# Move the model to the appropriate device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Generate random input data for profiling\n",
    "inputs = torch.randn(input_shape).to(device)\n",
    "\n",
    "# Calculate FLOPS\n",
    "flops, params = profile(model, inputs=(inputs,), verbose=False)\n",
    "\n",
    "print(f\"FLOPS: {flops / (10**6):.2f} million\")\n",
    "print(f\"Number of parameters: {params / (10**6):.2f} million\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "201eabcf-dad5-49df-ad63-19adbd249952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 0: Class Label - Common wheat\n",
      "Index 1: Class Label - Convolvulus arvensis\n",
      "Index 2: Class Label - Cotton\n",
      "Index 3: Class Label - Euphorbia peplus\n",
      "Index 4: Class Label - Grass\n",
      "Index 5: Class Label - Lolium multiflorum\n",
      "Index 6: Class Label - Maize\n",
      "Index 7: Class Label - Nutgrass\n",
      "Index 8: Class Label - Purslane\n",
      "Index 9: Class Label - Sesame\n",
      "Index 10: Class Label - Sugar beet\n",
      "Index 11: Class Label - Tomato\n"
     ]
    }
   ],
   "source": [
    "# Get class labels\n",
    "class_labels = train_dataset.classes\n",
    "\n",
    "# Print class labels with their index\n",
    "for i, label in enumerate(class_labels):\n",
    "    print(f\"Index {i}: Class Label - {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb556ba0-0fcc-4ac9-874c-8a548845fd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|████████████████████████████████████████████████████████████████████| 123/123 [00:32<00:00,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class Common wheat: 85.00%\n",
      "Accuracy for class Convolvulus arvensis: 100.00%\n",
      "Accuracy for class Cotton: 99.49%\n",
      "Accuracy for class Euphorbia peplus: 99.64%\n",
      "Accuracy for class Grass: 99.62%\n",
      "Accuracy for class Lolium multiflorum: 99.77%\n",
      "Accuracy for class Maize: 99.09%\n",
      "Accuracy for class Nutgrass: 98.41%\n",
      "Accuracy for class Purslane: 100.00%\n",
      "Accuracy for class Sesame: 99.15%\n",
      "Accuracy for class Sugar beet: 98.56%\n",
      "Accuracy for class Tomato: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#to test each class prediction accuracy\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),  # Convert images to tensors\n",
    "])\n",
    "\n",
    "class_labels = train_dataset.classes\n",
    "\n",
    "# Load dataset\n",
    "val_size = datasets.ImageFolder(root=r\"C:\\Users\\aliof\\OneDrive\\Desktop\\processed resized data\\augmented ali data\\balanced_dataset\\test\", transform=transform)\n",
    "\n",
    "# Create data loader for validation set\n",
    "val_loader = DataLoader(val_size, batch_size=32, shuffle=False)\n",
    "\n",
    "# Optionally, move the model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Evaluate the model on the validation dataset\n",
    "model.eval()\n",
    "class_correct = [0] * num_classes\n",
    "class_total = [0] * num_classes\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "            if label == pred:\n",
    "                class_correct[label] += 1\n",
    "            class_total[label] += 1\n",
    "\n",
    "# Calculate accuracy for each class\n",
    "class_accuracy = [class_correct[i] / class_total[i] if class_total[i] != 0 else 0 for i in range(num_classes)]\n",
    "for i in range(num_classes):\n",
    "    print(f\"Accuracy for class {class_labels[i]}: {class_accuracy[i] * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddafbd80-a5bd-487f-b71c-09b87e02568b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|████████████████████████████████████████████████████████████████████| 123/123 [00:31<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for class Common wheat:\n",
      "  Precision: 0.94\n",
      "  Recall: 0.85\n",
      "  F1-score: 0.89\n",
      "Metrics for class Convolvulus arvensis:\n",
      "  Precision: 1.00\n",
      "  Recall: 1.00\n",
      "  F1-score: 1.00\n",
      "Metrics for class Cotton:\n",
      "  Precision: 1.00\n",
      "  Recall: 0.99\n",
      "  F1-score: 1.00\n",
      "Metrics for class Euphorbia peplus:\n",
      "  Precision: 1.00\n",
      "  Recall: 1.00\n",
      "  F1-score: 1.00\n",
      "Metrics for class Grass:\n",
      "  Precision: 1.00\n",
      "  Recall: 1.00\n",
      "  F1-score: 1.00\n",
      "Metrics for class Lolium multiflorum:\n",
      "  Precision: 0.98\n",
      "  Recall: 1.00\n",
      "  F1-score: 0.99\n",
      "Metrics for class Maize:\n",
      "  Precision: 0.97\n",
      "  Recall: 0.99\n",
      "  F1-score: 0.98\n",
      "Metrics for class Nutgrass:\n",
      "  Precision: 0.99\n",
      "  Recall: 0.98\n",
      "  F1-score: 0.99\n",
      "Metrics for class Purslane:\n",
      "  Precision: 1.00\n",
      "  Recall: 1.00\n",
      "  F1-score: 1.00\n",
      "Metrics for class Sesame:\n",
      "  Precision: 1.00\n",
      "  Recall: 0.99\n",
      "  F1-score: 0.99\n",
      "Metrics for class Sugar beet:\n",
      "  Precision: 0.99\n",
      "  Recall: 0.99\n",
      "  F1-score: 0.99\n",
      "Metrics for class Tomato:\n",
      "  Precision: 1.00\n",
      "  Recall: 1.00\n",
      "  F1-score: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Define lists to store metrics\n",
    "class_precision = []\n",
    "class_recall = []\n",
    "class_f1_score = []\n",
    "\n",
    "# Evaluate the model on the validation dataset\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate precision, recall, and F1-score for each class\n",
    "for i in range(num_classes):\n",
    "    precision = precision_score(true_labels, predictions, labels=[i], average='micro')\n",
    "    recall = recall_score(true_labels, predictions, labels=[i], average='micro')\n",
    "    f1 = f1_score(true_labels, predictions, labels=[i], average='micro')\n",
    "    class_precision.append(precision)\n",
    "    class_recall.append(recall)\n",
    "    class_f1_score.append(f1)\n",
    "    print(f\"Metrics for class {class_labels[i]}:\")\n",
    "    print(f\"  Precision: {precision:.2f}\")\n",
    "    print(f\"  Recall: {recall:.2f}\")\n",
    "    print(f\"  F1-score: {f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "276cf259-6db3-4d5e-b6ae-75c5d3312f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the path to your image:  \"C:\\Users\\aliof\\OneDrive\\Desktop\\tomatocut\\tomato-plant-1521836767.jpg\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class label: Purslane\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "\n",
    "# Define data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "    transforms.ToTensor(),          # Convert images to tensors\n",
    "])\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Define class labels\n",
    "class_labels = ['Lolium_multiflorum', 'Maize', 'Nutgrass', 'Purslane', 'Convolvulus_arvensis', 'cotton', 'euphorbia', \n",
    "                'sesame', 'sugarbeet', 'tomato', 'wheat']\n",
    "\n",
    "# Check if GPU is available and move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Prompt user for input image\n",
    "user_image_path = input(\"Enter the path to your image: \")\n",
    "user_image_path = user_image_path[1:-1]\n",
    "user_image = Image.open(user_image_path).convert('RGB')\n",
    "user_image_tensor = transform(user_image).unsqueeze(0).to(device)  # Move tensor to the same device as the model\n",
    "\n",
    "# Perform inference on user input image\n",
    "with torch.no_grad():\n",
    "    output = model(user_image_tensor)\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    predicted_class_index = predicted.item()\n",
    "    predicted_class_label = class_labels[predicted_class_index]\n",
    "\n",
    "print(f\"Predicted class label: {predicted_class_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12185068-e260-4570-8482-c494a8118b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: 0a9f2d5a-bc30-c5fd-4d6d-dc0b720e4b52.jpg\n",
      "Predicted Class: Euphorbia peplus\n",
      "Probability: 1.0\n",
      "--------------------------------------\n",
      "Image: 167.png\n",
      "Predicted Class: Maize\n",
      "Probability: 0.9999957084655762\n",
      "--------------------------------------\n",
      "Image: Common-purslane-seedling.jpg\n",
      "Predicted Class: Cotton\n",
      "Probability: 0.980504035949707\n",
      "--------------------------------------\n",
      "Image: corn-seedlings.jpg\n",
      "Predicted Class: Maize\n",
      "Probability: 0.8510175943374634\n",
      "--------------------------------------\n",
      "Image: download.jpg\n",
      "Predicted Class: Sugar beet\n",
      "Probability: 0.43086370825767517\n",
      "--------------------------------------\n",
      "Image: DSC_0186.JPG\n",
      "Predicted Class: Tomato\n",
      "Probability: 0.999582827091217\n",
      "--------------------------------------\n",
      "Image: DSC_0190.JPG\n",
      "Predicted Class: Tomato\n",
      "Probability: 0.9746221303939819\n",
      "--------------------------------------\n",
      "Image: euphorbiapeplus10.jpg\n",
      "Predicted Class: Purslane\n",
      "Probability: 0.9999998807907104\n",
      "--------------------------------------\n",
      "Image: Euphorbia_peplus_seedling.jpg\n",
      "Predicted Class: Purslane\n",
      "Probability: 0.9984627962112427\n",
      "--------------------------------------\n",
      "Image: istockphoto-1406725806-612x612.jpg\n",
      "Predicted Class: Cotton\n",
      "Probability: 0.9985402822494507\n",
      "--------------------------------------\n",
      "Image: P1050280-700x525.jpg\n",
      "Predicted Class: Purslane\n",
      "Probability: 0.9979199767112732\n",
      "--------------------------------------\n",
      "Image: photo05.jpg\n",
      "Predicted Class: Cotton\n",
      "Probability: 0.9946616291999817\n",
      "--------------------------------------\n",
      "Image: PP-Growing-Tomatoes-from-Seed-header.jpg\n",
      "Predicted Class: Nutgrass\n",
      "Probability: 0.8237425088882446\n",
      "--------------------------------------\n",
      "Image: purslane-02.jpg\n",
      "Predicted Class: Purslane\n",
      "Probability: 1.0\n",
      "--------------------------------------\n",
      "Image: Purslane-scaled.jpg\n",
      "Predicted Class: Purslane\n",
      "Probability: 1.0\n",
      "--------------------------------------\n",
      "Image: seedling-cotton.jpg\n",
      "Predicted Class: Cotton\n",
      "Probability: 0.9996978044509888\n",
      "--------------------------------------\n",
      "Image: Small-Purslane-Plant-Transplanted-into-the-Garden.jpg\n",
      "Predicted Class: Purslane\n",
      "Probability: 1.0\n",
      "--------------------------------------\n",
      "Image: tomato-plant-1521836767.jpg\n",
      "Predicted Class: Sesame\n",
      "Probability: 0.8254152536392212\n",
      "--------------------------------------\n",
      "Image: Tomato_27_days_from_planting_seeds.jpg\n",
      "Predicted Class: Purslane\n",
      "Probability: 0.359861820936203\n",
      "--------------------------------------\n",
      "Image: top-view-closeup-of-a-row-of-sugar-beet-sprouts-700-258456776.jpg\n",
      "Predicted Class: Tomato\n",
      "Probability: 0.7530341744422913\n",
      "--------------------------------------\n",
      "Image: WhatsApp Image 2024-04-11 at 15.44.43_fbd74ba2.JPG\n",
      "Predicted Class: Cotton\n",
      "Probability: 0.9350759983062744\n",
      "--------------------------------------\n",
      "Image: WhatsApp Image 2024-04-11 at 15.53.00_e9c42601.jpg\n",
      "Predicted Class: Cotton\n",
      "Probability: 0.9389902949333191\n",
      "--------------------------------------\n",
      "Image: WhatsApp Image 2024-04-11 at 16.02.24_b72e6779.jpg\n",
      "Predicted Class: Euphorbia peplus\n",
      "Probability: 0.514837384223938\n",
      "--------------------------------------\n",
      "Image: Young-Seedling-Ready-to-Transplant.jpg\n",
      "Predicted Class: Sugar beet\n",
      "Probability: 0.5007549524307251\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Define the transformation for the input image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Define the model\n",
    "class ModifiedVGG16(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ModifiedVGG16, self).__init__()\n",
    "        self.features = torchvision.models.vgg16(pretrained=True).features\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 1 * 1, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes),  # Fix here\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "num_classes = len(train_dataset.classes)  # Define the number of classes\n",
    "model = ModifiedVGG16(num_classes)\n",
    "\n",
    "model.load_state_dict(torch.load(r\"C:\\Users\\aliof\\models\\vgg16\\best_model_paper.pt\"))  # Load your trained MobileNetV3 model here\n",
    "model.eval()\n",
    "\n",
    "# Folder containing images\n",
    "folder_path = r\"C:\\Users\\aliof\\OneDrive\\Desktop\\tomatocut\"\n",
    "\n",
    "# Iterate over each image in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\") or filename.endswith(\".JPG\"):\n",
    "        image_path = os.path.join(folder_path, filename)\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        # Apply transformations\n",
    "        input_image = transform(image).unsqueeze(0)  # Add a batch dimension\n",
    "\n",
    "        # Use GPU if available\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        input_image = input_image.to(device)\n",
    "        model = model.to(device)\n",
    "\n",
    "        # Get predictions\n",
    "        with torch.no_grad():\n",
    "            output = model(input_image)\n",
    "            probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "            predicted_class = torch.argmax(probabilities).item()\n",
    "\n",
    "\n",
    "\n",
    "        # Print prediction for each image\n",
    "        print(\"Image:\", filename)\n",
    "        print(\"Predicted Class:\", class_labels[predicted_class])\n",
    "        print(\"Probability:\", probabilities[predicted_class].item())\n",
    "        print(\"--------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225cecae-0b33-4b6e-bbe7-bc98c6bdcc51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
