{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3901719-2f50-47dc-adce-36601441174f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aliof\\anacondaLocation\\envs\\tourchgpu\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\aliof\\anacondaLocation\\envs\\tourchgpu\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Epoch 1/50: 100%|████████████████████████████████████████| 750/750 [04:35<00:00,  2.72it/s, accuracy=80.5, loss=0.0137]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Validation Loss: 0.1342, Validation Accuracy: 96.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|███████████████████████████████████████| 750/750 [04:33<00:00,  2.74it/s, accuracy=96.5, loss=0.00218]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Validation Loss: 0.0556, Validation Accuracy: 98.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: 100%|███████████████████████████████████████| 750/750 [04:33<00:00,  2.74it/s, accuracy=97.9, loss=0.00114]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], Validation Loss: 0.0387, Validation Accuracy: 98.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: 100%|██████████████████████████████████████| 750/750 [04:33<00:00,  2.74it/s, accuracy=98.7, loss=0.000737]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], Validation Loss: 0.0325, Validation Accuracy: 99.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: 100%|████████████████████████████████████████| 750/750 [04:34<00:00,  2.73it/s, accuracy=99, loss=0.000524]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Validation Loss: 0.0279, Validation Accuracy: 99.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: 100%|██████████████████████████████████████| 750/750 [04:35<00:00,  2.73it/s, accuracy=99.2, loss=0.000401]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], Validation Loss: 0.0278, Validation Accuracy: 99.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: 100%|██████████████████████████████████████| 750/750 [04:35<00:00,  2.72it/s, accuracy=99.4, loss=0.000315]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50], Validation Loss: 0.0256, Validation Accuracy: 99.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50: 100%|██████████████████████████████████████| 750/750 [04:34<00:00,  2.74it/s, accuracy=99.6, loss=0.000238]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Validation Loss: 0.0261, Validation Accuracy: 99.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50: 100%|██████████████████████████████████████| 750/750 [04:37<00:00,  2.70it/s, accuracy=99.7, loss=0.000193]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50], Validation Loss: 0.0256, Validation Accuracy: 99.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50: 100%|█████████████████████████████████████| 750/750 [04:45<00:00,  2.63it/s, accuracy=99.7, loss=0.000154]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss did not improve for 3 epochs. Early stopping...\n"
     ]
    }
   ],
   "source": [
    "#mobilenetv3\n",
    "#training process skip if you have the weights and run the below cell\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "    transforms.ToTensor(),          # Convert images to tensors\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "train_size = datasets.ImageFolder(root=r\"C:\\Users\\aliof\\OneDrive\\Desktop\\faculity project\\processed resized data\\augmented ali data\\balanced_dataset\\train\", transform=transform)\n",
    "val_size = datasets.ImageFolder(root=r\"C:\\Users\\aliof\\OneDrive\\Desktop\\faculity project\\processed resized data\\augmented ali data\\balanced_dataset\\valid\", transform=transform)\n",
    "\n",
    "# Split dataset into training and validation sets\n",
    "# train_size = int(0.8 * len(dataset))  # Use 80% of the data for training\n",
    "# val_size = len(dataset) - train_size  # Use the remaining 20% for validation\n",
    "# train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_size, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_size, batch_size=64, shuffle=False)\n",
    "\n",
    "# Load pre-trained MobileNetV3 model\n",
    "model = torchvision.models.mobilenet_v3_large(pretrained=True)\n",
    "\n",
    "# Modify the model's top layers for your specific task\n",
    "num_classes = len(train_size.classes)  # Number of classes in your dataset\n",
    "model.classifier[3] = torch.nn.Linear(model .classifier[3].in_features, num_classes)\n",
    "\n",
    "# Optionally, move the model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
    "num_epochs = 50\n",
    "\n",
    "# Initialize early stopping variables\n",
    "best_val_loss = float('inf')\n",
    "patience = 3  # Number of epochs to wait for validation loss improvement\n",
    "counter = 0\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=True) as t:\n",
    "        for inputs, labels in t:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            t.set_postfix(loss=running_loss / total, accuracy=100 * correct / total)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "    \n",
    "    # Compute average validation loss and accuracy\n",
    "    val_loss /= len(val_loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    \n",
    "    # Check for early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        counter = 0  # Reset counter\n",
    "        # Save the model's state\n",
    "        torch.save(model.state_dict(), 'best_model_paper.pth')\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(f'Validation loss did not improve for {patience} epochs. Early stopping...')\n",
    "            break\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a97b73a-da8f-4502-a5a1-3a3c271fc2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLOPS: 233.57 million\n",
      "Number of parameters: 4.22 million\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aliof\\anacondaLocation\\envs\\tourchgpu\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from thop import profile\n",
    "from torchvision.models import mobilenet_v3_large\n",
    "\n",
    "# Load the pre-trained MobileNetV3 model\n",
    "model = mobilenet_v3_large(pretrained=True)\n",
    "\n",
    "# Modify the model's top layers for your specific task\n",
    "num_classes = 11  # Number of classes in your dataset\n",
    "model.classifier[3] = torch.nn.Linear(model.classifier[3].in_features, num_classes)\n",
    "\n",
    "#load our trained model\n",
    "#model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# Define input tensor shape (batch_size, channels, height, width)\n",
    "input_shape = (1, 3, 224, 224)  # Assuming input images are RGB with size 224x224\n",
    "\n",
    "# Move the model to the appropriate device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Generate random input data for profiling\n",
    "inputs = torch.randn(input_shape).to(device)\n",
    "\n",
    "# Calculate FLOPS\n",
    "flops, params = profile(model, inputs=(inputs,), verbose=False)\n",
    "\n",
    "print(f\"FLOPS: {flops / (10**6):.2f} million\")\n",
    "print(f\"Number of parameters: {params / (10**6):.2f} million\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201eabcf-dad5-49df-ad63-19adbd249952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class labels\n",
    "class_labels = train_size.classes\n",
    "\n",
    "# Print class labels with their index\n",
    "for i, label in enumerate(class_labels):\n",
    "    print(f\"Index {i}: Class Label - {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb556ba0-0fcc-4ac9-874c-8a548845fd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00,  8.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class Common wheat: 90.91%\n",
      "Accuracy for class Convolvulus arvensis: 100.00%\n",
      "Accuracy for class Cotton: 75.00%\n",
      "Accuracy for class Euphorbia peplus: 14.29%\n",
      "Accuracy for class Grass: 100.00%\n",
      "Accuracy for class Lolium multiflorum: 100.00%\n",
      "Accuracy for class Maize: 100.00%\n",
      "Accuracy for class Nutgrass: 96.43%\n",
      "Accuracy for class Purslane: 100.00%\n",
      "Accuracy for class Sesame: 100.00%\n",
      "Accuracy for class Sugar beet: 75.00%\n",
      "Accuracy for class Tomato: 71.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#to test each class prediction accuracy\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),  # Convert images to tensors\n",
    "])\n",
    "\n",
    "class_labels = train_size.classes\n",
    "\n",
    "# Load dataset\n",
    "val_size = datasets.ImageFolder(root=r\"C:\\Users\\aliof\\OneDrive\\Desktop\\faculity project\\test\\New folder\", transform=transform)\n",
    "\n",
    "# Create data loader for validation set\n",
    "val_loader = DataLoader(val_size, batch_size=32, shuffle=False)\n",
    "\n",
    "# Load pre-trained MobileNetV3 model\n",
    "model = torchvision.models.mobilenet_v3_large(pretrained=False)\n",
    "\n",
    "# Modify the model's top layers for your specific task\n",
    "num_classes = len(val_size.classes)  # Number of classes in your dataset\n",
    "model.classifier[3] = torch.nn.Linear(model.classifier[3].in_features, num_classes)\n",
    "\n",
    "# Load the best model weights\n",
    "model.load_state_dict(torch.load('best_model_paper.pth'))\n",
    "\n",
    "# Optionally, move the model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Evaluate the model on the validation dataset\n",
    "model.eval()\n",
    "class_correct = [0] * num_classes\n",
    "class_total = [0] * num_classes\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "            if label == pred:\n",
    "                class_correct[label] += 1\n",
    "            class_total[label] += 1\n",
    "\n",
    "# Calculate accuracy for each class\n",
    "class_accuracy = [class_correct[i] / class_total[i] if class_total[i] != 0 else 0 for i in range(num_classes)]\n",
    "for i in range(num_classes):\n",
    "    print(f\"Accuracy for class {class_labels[i]}: {class_accuracy[i] * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddafbd80-a5bd-487f-b71c-09b87e02568b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00,  8.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for class Common wheat:\n",
      "  Precision: 1.00\n",
      "  Recall: 0.91\n",
      "  F1-score: 0.95\n",
      "Metrics for class Convolvulus arvensis:\n",
      "  Precision: 1.00\n",
      "  Recall: 1.00\n",
      "  F1-score: 1.00\n",
      "Metrics for class Cotton:\n",
      "  Precision: 0.25\n",
      "  Recall: 0.75\n",
      "  F1-score: 0.38\n",
      "Metrics for class Euphorbia peplus:\n",
      "  Precision: 1.00\n",
      "  Recall: 0.14\n",
      "  F1-score: 0.25\n",
      "Metrics for class Grass:\n",
      "  Precision: 1.00\n",
      "  Recall: 1.00\n",
      "  F1-score: 1.00\n",
      "Metrics for class Lolium multiflorum:\n",
      "  Precision: 0.97\n",
      "  Recall: 1.00\n",
      "  F1-score: 0.98\n",
      "Metrics for class Maize:\n",
      "  Precision: 0.80\n",
      "  Recall: 1.00\n",
      "  F1-score: 0.89\n",
      "Metrics for class Nutgrass:\n",
      "  Precision: 1.00\n",
      "  Recall: 0.96\n",
      "  F1-score: 0.98\n",
      "Metrics for class Purslane:\n",
      "  Precision: 0.25\n",
      "  Recall: 1.00\n",
      "  F1-score: 0.40\n",
      "Metrics for class Sesame:\n",
      "  Precision: 0.95\n",
      "  Recall: 1.00\n",
      "  F1-score: 0.98\n",
      "Metrics for class Sugar beet:\n",
      "  Precision: 1.00\n",
      "  Recall: 0.75\n",
      "  F1-score: 0.86\n",
      "Metrics for class Tomato:\n",
      "  Precision: 1.00\n",
      "  Recall: 0.71\n",
      "  F1-score: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Define lists to store metrics\n",
    "class_precision = []\n",
    "class_recall = []\n",
    "class_f1_score = []\n",
    "\n",
    "# Evaluate the model on the validation dataset\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate precision, recall, and F1-score for each class\n",
    "for i in range(num_classes):\n",
    "    precision = precision_score(true_labels, predictions, labels=[i], average='micro')\n",
    "    recall = recall_score(true_labels, predictions, labels=[i], average='micro')\n",
    "    f1 = f1_score(true_labels, predictions, labels=[i], average='micro')\n",
    "    class_precision.append(precision)\n",
    "    class_recall.append(recall)\n",
    "    class_f1_score.append(f1)\n",
    "    print(f\"Metrics for class {class_labels[i]}:\")\n",
    "    print(f\"  Precision: {precision:.2f}\")\n",
    "    print(f\"  Recall: {recall:.2f}\")\n",
    "    print(f\"  F1-score: {f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156ef711-f853-4d7f-a8bf-688615273353",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
