{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7a7a830-b11f-4361-ba09-99d6c80db601",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aliof\\anacondaLocation\\envs\\tourchgpu\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Small_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Epoch 1/50: 100%|███████████████████████████████████████| 375/375 [05:18<00:00,  1.18it/s, accuracy=90.9, loss=0.00275]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Validation Loss: 0.0792, Validation Accuracy: 97.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|██████████████████████████████████████| 375/375 [02:13<00:00,  2.81it/s, accuracy=98.5, loss=0.000384]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Validation Loss: 0.0466, Validation Accuracy: 98.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: 100%|██████████████████████████████████████| 375/375 [02:13<00:00,  2.81it/s, accuracy=99.3, loss=0.000193]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], Validation Loss: 0.0388, Validation Accuracy: 99.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: 100%|██████████████████████████████████████| 375/375 [02:13<00:00,  2.80it/s, accuracy=99.6, loss=0.000104]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], Validation Loss: 0.0431, Validation Accuracy: 99.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: 100%|███████████████████████████████████████| 375/375 [02:13<00:00,  2.80it/s, accuracy=99.7, loss=7.26e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Validation Loss: 0.0486, Validation Accuracy: 98.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50:   7%|██▉                                     | 28/375 [00:10<02:09,  2.68it/s, accuracy=99.8, loss=4.73e-5]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 65\u001b[0m\n\u001b[0;32m     63\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     64\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 65\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     66\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     67\u001b[0m total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#mobilenetv3\n",
    "#training process skip if you have the weights and run the below cell\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "    transforms.ToTensor(),          # Convert images to tensors\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "train_size = datasets.ImageFolder(root=r\"C:\\Users\\aliof\\OneDrive\\Desktop\\processed resized data\\augmented ali data\\balanced_dataset\\train\", transform=transform)\n",
    "val_size = datasets.ImageFolder(root=r\"C:\\Users\\aliof\\OneDrive\\Desktop\\processed resized data\\augmented ali data\\balanced_dataset\\valid\", transform=transform)\n",
    "\n",
    "# Split dataset into training and validation sets\n",
    "# train_size = int(0.8 * len(dataset))  # Use 80% of the data for training\n",
    "# val_size = len(dataset) - train_size  # Use the remaining 20% for validation\n",
    "# train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_size, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_size, batch_size=128, shuffle=False)\n",
    "\n",
    "# Load pre-trained MobileNetV3 model\n",
    "model = torchvision.models.mobilenet_v3_small(pretrained=True)\n",
    "\n",
    "# Modify the model's top layers for your specific task\n",
    "num_classes = len(train_size.classes)  # Number of classes in your dataset\n",
    "model.classifier[3] = torch.nn.Linear(model.classifier[3].in_features, num_classes)\n",
    "\n",
    "# Optionally, move the model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "num_epochs = 50\n",
    "\n",
    "# Initialize early stopping variables\n",
    "best_val_loss = float('inf')\n",
    "patience = 7  # Number of epochs to wait for validation loss improvement\n",
    "counter = 0\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=True) as t:\n",
    "        for inputs, labels in t:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            t.set_postfix(loss=running_loss / total, accuracy=100 * correct / total)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "    \n",
    "    # Compute average validation loss and accuracy\n",
    "    val_loss /= len(val_loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    \n",
    "    # Check for early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        counter = 0  # Reset counter\n",
    "        # Save the model's state\n",
    "        torch.save(model.state_dict(), r\"C:\\Users\\aliof\\models\\mobilenetv3small\\best_model_paper.pth\")\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(f'Validation loss did not improve for {patience} epochs. Early stopping...')\n",
    "            break\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eede1345-11b7-43a6-9951-b424de1f30f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLOPS: 61.47 million\n",
      "Number of parameters: 1.53 million\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from thop import profile\n",
    "from torchvision.models import mobilenet_v3_small\n",
    "\n",
    "# Load the pre-trained MobileNetV3 model\n",
    "model = mobilenet_v3_small(pretrained=False)\n",
    "\n",
    "# Modify the model's top layers for your specific task\n",
    "num_classes = 12  # Number of classes in your dataset\n",
    "model.classifier[3] = torch.nn.Linear(model.classifier[3].in_features, num_classes)\n",
    "\n",
    "#load our trained model\n",
    "model.load_state_dict(torch.load(r\"C:\\Users\\aliof\\models\\mobilenetv3small\\best_model_paper.pth\"))\n",
    "\n",
    "# Define input tensor shape (batch_size, channels, height, width)\n",
    "input_shape = (1, 3, 224, 224)  # Assuming input images are RGB with size 224x224\n",
    "\n",
    "# Move the model to the appropriate device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Generate random input data for profiling\n",
    "inputs = torch.randn(input_shape).to(device)\n",
    "\n",
    "# Calculate FLOPS\n",
    "flops, params = profile(model, inputs=(inputs,), verbose=False)\n",
    "\n",
    "print(f\"FLOPS: {flops / (10**6):.2f} million\")\n",
    "print(f\"Number of parameters: {params / (10**6):.2f} million\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e35bf5c1-e418-4b2a-b9a9-899edd259390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 0: Class Label - Common wheat\n",
      "Index 1: Class Label - Convolvulus arvensis\n",
      "Index 2: Class Label - Cotton\n",
      "Index 3: Class Label - Euphorbia peplus\n",
      "Index 4: Class Label - Grass\n",
      "Index 5: Class Label - Lolium multiflorum\n",
      "Index 6: Class Label - Maize\n",
      "Index 7: Class Label - Nutgrass\n",
      "Index 8: Class Label - Purslane\n",
      "Index 9: Class Label - Sesame\n",
      "Index 10: Class Label - Sugar beet\n",
      "Index 11: Class Label - Tomato\n"
     ]
    }
   ],
   "source": [
    "train_size = datasets.ImageFolder(root=r\"C:\\Users\\aliof\\OneDrive\\Desktop\\faculity project\\test\\New folder\", transform=transform)\n",
    "# Get class labels\n",
    "class_labels = train_size.classes\n",
    "\n",
    "# Print class labels with their index\n",
    "for i, label in enumerate(class_labels):\n",
    "    print(f\"Index {i}: Class Label - {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51af13d6-9824-4d68-b7d4-7bcb39aacec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aliof\\anacondaLocation\\envs\\tourchgpu\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\aliof\\anacondaLocation\\envs\\tourchgpu\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████████████| 6/6 [00:03<00:00,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class Common wheat: 90.91%\n",
      "Accuracy for class Convolvulus arvensis: 100.00%\n",
      "Accuracy for class Cotton: 25.00%\n",
      "Accuracy for class Euphorbia peplus: 7.14%\n",
      "Accuracy for class Grass: 100.00%\n",
      "Accuracy for class Lolium multiflorum: 100.00%\n",
      "Accuracy for class Maize: 100.00%\n",
      "Accuracy for class Nutgrass: 100.00%\n",
      "Accuracy for class Purslane: 100.00%\n",
      "Accuracy for class Sesame: 100.00%\n",
      "Accuracy for class Sugar beet: 75.00%\n",
      "Accuracy for class Tomato: 42.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#to test each class prediction accuracy\n",
    "import torchvision\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),  # Convert images to tensors\n",
    "])\n",
    "\n",
    "class_labels = train_size.classes\n",
    "\n",
    "# Load dataset\n",
    "val_size = datasets.ImageFolder(root=r\"C:\\Users\\aliof\\OneDrive\\Desktop\\faculity project\\test\\New folder\", transform=transform)\n",
    "\n",
    "# Create data loader for validation set\n",
    "val_loader = DataLoader(val_size, batch_size=32, shuffle=False)\n",
    "\n",
    "# Load pre-trained MobileNetV3 model\n",
    "model = torchvision.models.mobilenet_v3_small(pretrained=False)\n",
    "\n",
    "# Modify the model's top layers for your specific task\n",
    "num_classes = len(val_size.classes)  # Number of classes in your dataset\n",
    "model.classifier[3] = torch.nn.Linear(model.classifier[3].in_features, num_classes)\n",
    "\n",
    "# Load the best model weights\n",
    "model.load_state_dict(torch.load(r\"C:\\Users\\aliof\\models\\mobilenetv3small\\best_model_paper.pth\"))\n",
    "\n",
    "# Optionally, move the model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Evaluate the model on the validation dataset\n",
    "model.eval()\n",
    "class_correct = [0] * num_classes\n",
    "class_total = [0] * num_classes\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "            if label == pred:\n",
    "                class_correct[label] += 1\n",
    "            class_total[label] += 1\n",
    "\n",
    "# Calculate accuracy for each class\n",
    "class_accuracy = [class_correct[i] / class_total[i] if class_total[i] != 0 else 0 for i in range(num_classes)]\n",
    "for i in range(num_classes):\n",
    "    print(f\"Accuracy for class {class_labels[i]}: {class_accuracy[i] * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5ab8221-059f-4d6b-a6bb-42f0bb359a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 10.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for class Common wheat:\n",
      "  Precision: 1.00\n",
      "  Recall: 0.91\n",
      "  F1-score: 0.95\n",
      "Metrics for class Convolvulus arvensis:\n",
      "  Precision: 1.00\n",
      "  Recall: 1.00\n",
      "  F1-score: 1.00\n",
      "Metrics for class Cotton:\n",
      "  Precision: 0.25\n",
      "  Recall: 0.25\n",
      "  F1-score: 0.25\n",
      "Metrics for class Euphorbia peplus:\n",
      "  Precision: 1.00\n",
      "  Recall: 0.07\n",
      "  F1-score: 0.13\n",
      "Metrics for class Grass:\n",
      "  Precision: 1.00\n",
      "  Recall: 1.00\n",
      "  F1-score: 1.00\n",
      "Metrics for class Lolium multiflorum:\n",
      "  Precision: 1.00\n",
      "  Recall: 1.00\n",
      "  F1-score: 1.00\n",
      "Metrics for class Maize:\n",
      "  Precision: 0.57\n",
      "  Recall: 1.00\n",
      "  F1-score: 0.73\n",
      "Metrics for class Nutgrass:\n",
      "  Precision: 1.00\n",
      "  Recall: 1.00\n",
      "  F1-score: 1.00\n",
      "Metrics for class Purslane:\n",
      "  Precision: 0.25\n",
      "  Recall: 1.00\n",
      "  F1-score: 0.40\n",
      "Metrics for class Sesame:\n",
      "  Precision: 0.88\n",
      "  Recall: 1.00\n",
      "  F1-score: 0.93\n",
      "Metrics for class Sugar beet:\n",
      "  Precision: 0.60\n",
      "  Recall: 0.75\n",
      "  F1-score: 0.67\n",
      "Metrics for class Tomato:\n",
      "  Precision: 0.38\n",
      "  Recall: 0.43\n",
      "  F1-score: 0.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Define lists to store metrics\n",
    "class_precision = []\n",
    "class_recall = []\n",
    "class_f1_score = []\n",
    "\n",
    "# Evaluate the model on the validation dataset\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate precision, recall, and F1-score for each class\n",
    "for i in range(num_classes):\n",
    "    precision = precision_score(true_labels, predictions, labels=[i], average='micro')\n",
    "    recall = recall_score(true_labels, predictions, labels=[i], average='micro')\n",
    "    f1 = f1_score(true_labels, predictions, labels=[i], average='micro')\n",
    "    class_precision.append(precision)\n",
    "    class_recall.append(recall)\n",
    "    class_f1_score.append(f1)\n",
    "    print(f\"Metrics for class {class_labels[i]}:\")\n",
    "    print(f\"  Precision: {precision:.2f}\")\n",
    "    print(f\"  Recall: {recall:.2f}\")\n",
    "    print(f\"  F1-score: {f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "654ca3d3-8351-4321-9d8c-34448d0c9805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: 0a9f2d5a-bc30-c5fd-4d6d-dc0b720e4b52.jpg\n",
      "Predicted Class: Euphorbia peplus\n",
      "Probability: 0.9999961853027344\n",
      "--------------------------------------\n",
      "Image: 167.png\n",
      "Predicted Class: Maize\n",
      "Probability: 0.9998841285705566\n",
      "--------------------------------------\n",
      "Image: Common-purslane-seedling.jpg\n",
      "Predicted Class: Convolvulus arvensis\n",
      "Probability: 0.22329333424568176\n",
      "--------------------------------------\n",
      "Image: corn-seedlings.jpg\n",
      "Predicted Class: Maize\n",
      "Probability: 0.9269290566444397\n",
      "--------------------------------------\n",
      "Image: download.jpg\n",
      "Predicted Class: Sugar beet\n",
      "Probability: 0.994665265083313\n",
      "--------------------------------------\n",
      "Image: DSC_0186.JPG\n",
      "Predicted Class: Tomato\n",
      "Probability: 0.9997785687446594\n",
      "--------------------------------------\n",
      "Image: DSC_0190.JPG\n",
      "Predicted Class: Tomato\n",
      "Probability: 0.9986100196838379\n",
      "--------------------------------------\n",
      "Image: euphorbiapeplus10.jpg\n",
      "Predicted Class: Tomato\n",
      "Probability: 0.6774348616600037\n",
      "--------------------------------------\n",
      "Image: Euphorbia_peplus_seedling.jpg\n",
      "Predicted Class: Purslane\n",
      "Probability: 0.7264078259468079\n",
      "--------------------------------------\n",
      "Image: istockphoto-1406725806-612x612.jpg\n",
      "Predicted Class: Cotton\n",
      "Probability: 0.9530785083770752\n",
      "--------------------------------------\n",
      "Image: P1050280-700x525.jpg\n",
      "Predicted Class: Purslane\n",
      "Probability: 0.999934196472168\n",
      "--------------------------------------\n",
      "Image: photo05.jpg\n",
      "Predicted Class: Tomato\n",
      "Probability: 0.9672292470932007\n",
      "--------------------------------------\n",
      "Image: PP-Growing-Tomatoes-from-Seed-header.jpg\n",
      "Predicted Class: Purslane\n",
      "Probability: 0.6314484477043152\n",
      "--------------------------------------\n",
      "Image: purslane-02.jpg\n",
      "Predicted Class: Purslane\n",
      "Probability: 0.959346354007721\n",
      "--------------------------------------\n",
      "Image: Purslane-scaled.jpg\n",
      "Predicted Class: Purslane\n",
      "Probability: 0.9999862909317017\n",
      "--------------------------------------\n",
      "Image: seedling-cotton.jpg\n",
      "Predicted Class: Cotton\n",
      "Probability: 0.8715125322341919\n",
      "--------------------------------------\n",
      "Image: Small-Purslane-Plant-Transplanted-into-the-Garden.jpg\n",
      "Predicted Class: Purslane\n",
      "Probability: 0.9992451667785645\n",
      "--------------------------------------\n",
      "Image: tomato-plant-1521836767.jpg\n",
      "Predicted Class: Tomato\n",
      "Probability: 0.4662952721118927\n",
      "--------------------------------------\n",
      "Image: Tomato_27_days_from_planting_seeds.jpg\n",
      "Predicted Class: Tomato\n",
      "Probability: 0.7742871642112732\n",
      "--------------------------------------\n",
      "Image: top-view-closeup-of-a-row-of-sugar-beet-sprouts-700-258456776.jpg\n",
      "Predicted Class: Sugar beet\n",
      "Probability: 0.9634117484092712\n",
      "--------------------------------------\n",
      "Image: WhatsApp Image 2024-04-11 at 15.44.43_fbd74ba2.JPG\n",
      "Predicted Class: Cotton\n",
      "Probability: 0.8444752097129822\n",
      "--------------------------------------\n",
      "Image: WhatsApp Image 2024-04-11 at 15.53.00_e9c42601.jpg\n",
      "Predicted Class: Sugar beet\n",
      "Probability: 0.4064156711101532\n",
      "--------------------------------------\n",
      "Image: WhatsApp Image 2024-04-11 at 16.02.24_b72e6779.jpg\n",
      "Predicted Class: Sugar beet\n",
      "Probability: 0.3341454863548279\n",
      "--------------------------------------\n",
      "Image: Young-Seedling-Ready-to-Transplant.jpg\n",
      "Predicted Class: Tomato\n",
      "Probability: 0.9399387240409851\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Define the transformation for the input image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load the trained model (MobileNetV3)\n",
    "model = models.mobilenet_v3_small(pretrained=False)\n",
    "\n",
    "# Modify the model's top layers for your specific task\n",
    "num_classes = 12  # Number of classes in your dataset\n",
    "model.classifier[3] = torch.nn.Linear(model.classifier[3].in_features, num_classes)\n",
    "\n",
    "model.load_state_dict(torch.load(r\"C:\\Users\\aliof\\models\\mobilenetv3small\\best_model_paper.pth\"))  # Load your trained MobileNetV3 model here\n",
    "model.eval()\n",
    "\n",
    "# Folder containing images\n",
    "folder_path = r\"C:\\Users\\aliof\\OneDrive\\Desktop\\tomatocut\"\n",
    "\n",
    "# Iterate over each image in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\") or filename.endswith(\".JPG\"):\n",
    "        image_path = os.path.join(folder_path, filename)\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        # Apply transformations\n",
    "        input_image = transform(image).unsqueeze(0)  # Add a batch dimension\n",
    "\n",
    "        # Use GPU if available\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        input_image = input_image.to(device)\n",
    "        model = model.to(device)\n",
    "\n",
    "        # Get predictions\n",
    "        with torch.no_grad():\n",
    "            output = model(input_image)\n",
    "            probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "            predicted_class = torch.argmax(probabilities).item()\n",
    "\n",
    "        class_labels = train_size.classes\n",
    "\n",
    "        # Print prediction for each image\n",
    "        print(\"Image:\", filename)\n",
    "        print(\"Predicted Class:\", class_labels[predicted_class])\n",
    "        print(\"Probability:\", probabilities[predicted_class].item())\n",
    "        print(\"--------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fa8782-3798-4cab-9b4c-34bf60602b42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
